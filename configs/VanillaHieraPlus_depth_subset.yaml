dataset_ratio: 0.4
batch_size: 64
scale: 1000.

model:
  name: HieraDPT
  out_chans: 1
  pretrained_model: "exp/HieraPretrainSimBasePlus/checkpoints/last.ckpt"

  hiera:
    embed_dim: 112
    num_heads: 2
    stages: [2, 3, 16, 3]
    q_pool: 2
    
    decoder: "Vanilla"
    decoder_embed_dim: 512
    decoder_num_heads: 16
    decoder_depth: 8

dataset:
  output_type: "depth"

optimizer:
  name: AdamW
  lr: 0.001

scheduler:
  name: linear_cosine
  warmup: 2000